package org.opentestsystem.rdw.admin.service.impl;

import com.amazonaws.services.s3.Headers;
import org.apache.commons.codec.binary.Hex;
import org.apache.commons.codec.digest.DigestUtils;
import org.opentestsystem.rdw.admin.model.StudentGroupBatch;
import org.opentestsystem.rdw.admin.repository.ImportRepository;
import org.opentestsystem.rdw.admin.service.GroupsSource;
import org.opentestsystem.rdw.admin.service.StudentGroupBatchService;
import org.opentestsystem.rdw.archive.ArchiveService;
import org.opentestsystem.rdw.common.model.ImportStatus;
import org.opentestsystem.rdw.common.model.LocationStrategy;
import org.opentestsystem.rdw.group.CsvValidationResult;
import org.opentestsystem.rdw.group.CsvValidationService;
import org.opentestsystem.rdw.reporting.common.security.User;
import org.opentestsystem.rdw.security.PermissionScope;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.stream.annotation.EnableBinding;
import org.springframework.cloud.stream.messaging.Source;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.io.InputStream;
import java.security.DigestInputStream;
import java.security.MessageDigest;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import static com.google.common.collect.Maps.newHashMap;
import static java.nio.charset.StandardCharsets.UTF_8;
import static org.opentestsystem.rdw.admin.security.AdminPermission.GroupWrite;
import static org.opentestsystem.rdw.group.CsvValidationResult.failure;

@Service
@EnableBinding(Source.class)
class DefaultStudentGroupBatchService implements StudentGroupBatchService {
    private static final Logger logger = LoggerFactory.getLogger(DefaultStudentGroupBatchService.class);

    private final ImportRepository repository;
    private final ArchiveService archiveService;
    private final CsvValidationService validationService;
    private final GroupsSource source;

    @Autowired
    public DefaultStudentGroupBatchService(final ImportRepository repository,
                                           final ArchiveService archiveService,
                                           final CsvValidationService validationService,
                                           final GroupsSource source) {
        this.repository = repository;
        this.archiveService = archiveService;
        this.validationService = validationService;
        this.source = source;
    }

    @Override
    public Iterable<StudentGroupBatch> findAllStudentGroupBatches(final User user) {
        return repository.findGroupByCreator(user.getUsername());
    }

    @Override
    public StudentGroupBatch upload(final User user, final MultipartFile file) {
        final String filename = file.getOriginalFilename();
        logger.debug("Processing upload request: {}", filename);

        final PermissionScope permissionScope = user
                .getPermissionsById()
                .get(GroupWrite)
                .getScope();

        // set known metadata ...
        final Map<String, String> metadata = newHashMap();
        metadata.put("filename", filename);
        metadata.put("username", user.getUsername());

        // validate and calculate the digest in one go ...
        final MessageDigest messageDigest = DigestUtils.getMd5Digest();
        final List<CsvValidationResult> validationResults;
        try (final DigestInputStream digestStream = new DigestInputStream(file.getInputStream(), messageDigest)) {
            validationResults = validationService.validate(digestStream, permissionScope, metadata);
        } catch (final IOException e) {
            // this only happens if we can't get the file input stream (i.e. not a validation error)
            logger.warn("Error reading GROUPS file {}: {}", file.getName(), e.getMessage());
            throw new IllegalArgumentException(e);
        }
        final String digest = Hex.encodeHexString(messageDigest.digest()).toUpperCase();

        // if we get this far, we want to archive the file and create the import
        // record even if there are validation errors ...
        final long importId;
        final StudentGroupBatch batch = repository.findGroupByDigest(digest);
        if (batch == null) {
            try (final InputStream fileStream = file.getInputStream()) {
                final String location = new LocationStrategy.GroupUploadContentLocationStrategy().location(digest);

                final Properties properties = new Properties();
                properties.putAll(metadata);
                properties.put(Headers.CONTENT_TYPE, file.getContentType());
                properties.put(Headers.CONTENT_LENGTH, file.getSize());

                archiveService.writeResource(location, fileStream, properties);

                logger.debug("Archived GROUPS file {} to {}", file.getOriginalFilename(), location);
            } catch (final IOException e) {
                validationResults.add(failure(0, "Error archiving GROUPS file " + filename + " to " + digest + ": " + e.getMessage()));
            }
            importId = repository.createGroupImport(file.getContentType(), digest, filename, user.getUsername());
        } else {
            importId = batch.getId();
        }

        final boolean failures = validationResults.stream().anyMatch(result -> !result.isOk());
        if (failures) {
            logger.info("Request failed validation: {}", filename);
            repository.setStatus(importId, ImportStatus.BAD_DATA, validationService.toFailureMessage(validationResults));
        } else {
            logger.debug("Validated request: {}", filename);
            repository.setStatus(importId, ImportStatus.ACCEPTED, validationService.toSuccessMessage(validationResults));
            // and, finally, trigger the processing of the file
            source.send(digest.getBytes(UTF_8), file.getContentType(), importId);
        }

        return repository.findGroupById(importId);
    }
}
