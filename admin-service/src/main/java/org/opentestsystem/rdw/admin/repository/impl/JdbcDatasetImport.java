package org.opentestsystem.rdw.admin.repository.impl;

import com.amazonaws.auth.AWSStaticCredentialsProvider;
import com.amazonaws.auth.BasicAWSCredentials;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3ClientBuilder;
import com.amazonaws.services.s3.model.S3Object;
import com.google.common.annotations.VisibleForTesting;
import org.apache.commons.io.FilenameUtils;
import org.apache.commons.io.IOUtils;
import org.opentestsystem.rdw.admin.repository.DatasetImport;
import org.opentestsystem.rdw.archive.ArchivePropertiesRoot;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.jdbc.core.JdbcOperations;
import org.springframework.jdbc.core.namedparam.MapSqlParameterSource;
import org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate;
import org.springframework.stereotype.Repository;

import java.util.Arrays;
import java.util.List;

@Repository
public class JdbcDatasetImport implements DatasetImport {

    private static final Logger logger = LoggerFactory.getLogger(JdbcDatasetImport.class);
    private final NamedParameterJdbcTemplate warehouseJdbcTemplate;
    private final ArchivePropertiesRoot archivePropertiesRoot;
    private final AmazonS3 amazonS3;

    @Autowired
    public JdbcDatasetImport(@Qualifier("warehouseJdbcTemplate") final NamedParameterJdbcTemplate warehouseJdbcTemplate,
                             final ArchivePropertiesRoot archivePropertiesRoot) {
        this.warehouseJdbcTemplate = warehouseJdbcTemplate;
        this.archivePropertiesRoot = archivePropertiesRoot;
        this.amazonS3 = AmazonS3ClientBuilder.standard()
                .withRegion(archivePropertiesRoot.getS3RegionStatic())
                .withCredentials(
                        new AWSStaticCredentialsProvider(
                                new BasicAWSCredentials(
                                        archivePropertiesRoot.getS3AccessKey(),
                                        archivePropertiesRoot.getS3SecretKey()
                                )
                        )
                )
                .build();
    }

    @Override
    public void loadDataset(String datasetName) {
        final JdbcOperations operations = warehouseJdbcTemplate.getJdbcOperations();
        final String sql = "LOAD DATA FROM S3 :s3_uri INTO TABLE ";
        operations.execute("SET FOREIGN_KEY_CHECKS=0");
        manifest(datasetName, "warehouse").forEach(t -> {
            logger.debug("table: {}", t);
            final String s3Uri = archivePropertiesRoot.getUriRoot() + "/sandbox-datasets/" + datasetName + "/warehouse/" + t;
            final String tableName = FilenameUtils.removeExtension(t);
            warehouseJdbcTemplate.update(sql + tableName, new MapSqlParameterSource()
                    .addValue("s3_uri", s3Uri));
        });
        operations.execute("SET FOREIGN_KEY_CHECKS=1");
    }

    @VisibleForTesting
    List<String> manifest(String datasetName, String databaseName) {
        try {
            final String bucketName = archivePropertiesRoot.getUriRoot().substring("s3://".length());
            logger.debug("bucketName: {}", bucketName);
            final String key = "sandbox-datasets/" + datasetName + "/" + databaseName + "/manifest.txt";
            logger.debug("key: {}", key);
            final S3Object s3Object = amazonS3.getObject(bucketName, key);
            final String manifestFile = IOUtils.toString(s3Object.getObjectContent(), "UTF-8");
            logger.debug("manifestFile: {}", manifestFile);
            return Arrays.asList(manifestFile.split("\n"));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

}
